<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>4 Using MACPO</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html,2,sections+ --> 
<meta name="src" content="user_manual.tex"> 
<meta name="date" content="2013-10-14 18:02:00"> 
<link rel="stylesheet" type="text/css" href="user_manual.css"> 
</head><body 
>
   <!--l. 1--><div class="crosslinks"><p class="noindent">[<a 
href="user_manualch3.html" >prev</a>] [<a 
href="user_manualch3.html#tailuser_manualch3.html" >prev-tail</a>] [<a 
href="#tailuser_manualch4.html">tail</a>] [<a 
href="user_manual.html# " >up</a>] </p></div>
   <h2 class="chapterHead"><span class="titlemark">Chapter&#x00A0;4</span><br /><a 
href="#x11-280004" id="x11-280004">Using MACPO</a></h2>
<!--l. 2--><p class="noindent" >MACPO is an acronym for Memory Access Characterization for Performance Optimization. It is a tool
that has been built to assist performance tuning of single- and multi-threaded C, C++ or Fortran
applications. More specifically, MACPO is designed to provide insight into an application&#8217;s memory usage
patterns.
   <h3 class="sectionHead"><span class="titlemark">4.1   </span> <a 
href="#x11-290004.1" id="x11-290004.1">A Quick Demonstration</a></h3>
<!--l. 5--><p class="noindent" >To demonstrate the functioning of MACPO, let&#8217;s consider an example program. This program uses Pthreads to
calculate the value of Pi using the Monte-Carlo method.
<!--l. 7--><p class="indent" >   The following code shows the function that is executed by each thread:
                                                                                         
                                                                                         
   <div class="verbatim" id="verbatim-21">
void*&#x00A0;thread_func&#x00A0;(void*&#x00A0;arg)&#x00A0;{
&#x00A0;<br />&#x00A0;&#x00A0;int&#x00A0;idx,&#x00A0;i,&#x00A0;repeat;
&#x00A0;<br />&#x00A0;&#x00A0;float&#x00A0;x,&#x00A0;y,&#x00A0;z;
&#x00A0;<br />&#x00A0;&#x00A0;thread_info_t*&#x00A0;thread_info&#x00A0;=&#x00A0;(thread_info_t*)&#x00A0;arg;
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;for&#x00A0;(repeat&#x00A0;=&#x00A0;0;&#x00A0;repeat&#x00A0;&#x003C;&#x00A0;REPEAT_COUNT;&#x00A0;repeat++)&#x00A0;{
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;(i&#x00A0;=&#x00A0;0;&#x00A0;i&#x00A0;&#x003C;&#x00A0;ITERATIONS;&#x00A0;i++)&#x00A0;{
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;idx&#x00A0;=&#x00A0;i&#x00A0;+&#x00A0;thread_info-&#x003E;tid;
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;x&#x00A0;=&#x00A0;random_numbers[idx&#x00A0;%&#x00A0;RANDOM_BUFFER_SIZE];
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;y&#x00A0;=&#x00A0;random_numbers[(1&#x00A0;+&#x00A0;idx)&#x00A0;%&#x00A0;RANDOM_BUFFER_SIZE];
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;z&#x00A0;=&#x00A0;x&#x00A0;*&#x00A0;x&#x00A0;+&#x00A0;y&#x00A0;*&#x00A0;y;
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;if&#x00A0;(z&#x00A0;&#x003C;=&#x00A0;1)&#x00A0;counts[thread_info-&#x003E;tid]++;
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;}
&#x00A0;<br />&#x00A0;&#x00A0;}
&#x00A0;<br />&#x00A0;&#x00A0;pthread_exit(0);
&#x00A0;<br />}
</div>
<!--l. 26--><p class="nopar" >
<!--l. 28--><p class="indent" >   To compile the application using MACPO, indicating that we are interested in understanding the performance
metrics associated with the <span 
class="cmtt-10">thread</span><span 
class="cmtt-10">_func </span>function, run the following commands:
                                                                                         
                                                                                         
   <div class="verbatim" id="verbatim-22">
$&#x00A0;macpo.sh&#x00A0;--macpo:function=thread_func&#x00A0;-c&#x00A0;monte-carlo.cc
&#x00A0;<br />$&#x00A0;macpo.sh&#x00A0;--macpo:function=thread_func&#x00A0;monte-carlo.o&#x00A0;-o&#x00A0;monte-carlo&#x00A0;-lpthread&#x00A0;-lrt
</div>
<!--l. 32--><p class="nopar" >
<!--l. 34--><p class="indent" >   Runtime logs (macpo.out) are produced when the application is run:
                                                                                         
                                                                                         
   <div class="verbatim" id="verbatim-23">
$&#x00A0;./monte-carlo
</div>
<!--l. 37--><p class="nopar" >
<!--l. 39--><p class="indent" >   To print performance metrics, use the <span 
class="cmtt-10">macpo-analyze </span>program.
                                                                                         
                                                                                         
   <div class="verbatim" id="verbatim-24">
$&#x00A0;macpo-analyze&#x00A0;macpo.out
</div>
<!--l. 42--><p class="nopar" >
<!--l. 44--><p class="indent" >   This will produce an output that is similar to the one shown below:
                                                                                         
                                                                                         
   <div class="verbatim" id="verbatim-25">
Var&#x00A0;"counts",&#x00A0;seen&#x00A0;1668&#x00A0;times,&#x00A0;estimated&#x00A0;to&#x00A0;cost&#x00A0;147.12&#x00A0;cycles&#x00A0;on&#x00A0;every&#x00A0;access.
&#x00A0;<br />Stride&#x00A0;of&#x00A0;0&#x00A0;cache&#x00A0;lines&#x00A0;was&#x00A0;observed&#x00A0;1585&#x00A0;times&#x00A0;(100.00%).
&#x00A0;<br />
&#x00A0;<br />Level&#x00A0;1&#x00A0;data&#x00A0;cache&#x00A0;conflicts&#x00A0;=&#x00A0;78.22%&#x00A0;[################################&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;]
&#x00A0;<br />Level&#x00A0;2&#x00A0;data&#x00A0;cache&#x00A0;conflicts&#x00A0;=&#x00A0;63.37%&#x00A0;[##########################&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;]
&#x00A0;<br />NUMA&#x00A0;data&#x00A0;conflicts&#x00A0;=&#x00A0;43.56%&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;[##################&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;]
&#x00A0;<br />
&#x00A0;<br />Level&#x00A0;1&#x00A0;data&#x00A0;cache&#x00A0;reuse&#x00A0;factor&#x00A0;=&#x00A0;97.0%&#x00A0;[#######################################&#x00A0;]
&#x00A0;<br />Level&#x00A0;2&#x00A0;data&#x00A0;cache&#x00A0;reuse&#x00A0;factor&#x00A0;=&#x00A0;3.0%&#x00A0;&#x00A0;[##&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;]
&#x00A0;<br />Level&#x00A0;3&#x00A0;data&#x00A0;cache&#x00A0;reuse&#x00A0;factor&#x00A0;=&#x00A0;0.0%&#x00A0;&#x00A0;[&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;]
</div>
<!--l. 56--><p class="nopar" >
<!--l. 58--><p class="indent" >   The output shows the estimated cost of memory accesses (147.12 cycles) to the variable <span 
class="cmtt-10">counts </span>in terms of cycles per
access<span class="footnote-mark"><a 
href="user_manual12.html#fn1x19"><sup class="textsuperscript">1</sup></a></span><a 
 id="x11-29001f1"></a> .
The output also shows stride values (0 cache lines) observed in the accesses to the
variable<span class="footnote-mark"><a 
href="user_manual13.html#fn2x19"><sup class="textsuperscript">2</sup></a></span><a 
 id="x11-29002f2"></a> . As
per the cache conflicts shown in the output, accesses to the variable <span 
class="cmtt-10">counts </span>suffer from both L1 and L2 cache
conflicts (also known as cache thrashing). Using this knowledge, we can pad the <span 
class="cmtt-10">counts </span>array (<span 
class="cmti-10">i.e.</span>, add dummy
bytes to the array) so that each thread running on a core and, thus, sharing an L1 cache as well as the shared L2
cache, which may be shared by other cores, accesses a different cache line. This optimization reduces the running
time of the <span 
class="cmtt-10">thread</span><span 
class="cmtt-10">_func </span>routine from 9.14s to 3.17s.
<!--l. 60--><p class="indent" >   The other information provided by MACPO is discussed below in Section <a 
href="#x11-310004.3">4.3<!--tex4ht:ref: sec:macpo-metrics --></a>.
   <h3 class="sectionHead"><span class="titlemark">4.2   </span> <a 
href="#x11-300004.2" id="x11-300004.2">When to Use MACPO</a></h3>
<!--l. 64--><p class="noindent" >MACPO may be useful to you in any of the following situations:
     <ul class="itemize1">
     <li class="itemize">Perfexpert reports that L2 or L3 data access LCPI is high.
     </li>
     <li class="itemize">Your program uses a lot of memory or it is memory-bound.
     </li>
     <li class="itemize">CPU profiling does not show any interesting results.</li></ul>
<!--l. 72--><p class="indent" >   If all (or most) of your application&#8217;s memory accesses are irregular, you may be able to infer the optimizations
applicable to your program. However, for such programs, MACPO metrics may not be able to assist you
directly.
                                                                                         
                                                                                         
<!--l. 74--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">4.3   </span> <a 
href="#x11-310004.3" id="x11-310004.3">MACPO Metrics</a></h3>
<!--l. 77--><p class="noindent" >Performance information shown by MACPO can be grouped into two parts. The first part shows information that is
applicable to the entire function being profiled. The second part shows information that is specific to the important
variables in the function.
<!--l. 79--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">4.3.1   </span> <a 
href="#x11-320004.3.1" id="x11-320004.3.1">Function-wide Performance Metrics</a></h4>
<!--l. 80--><p class="noindent" >Currently, function-wide information only shows the number of streams that were seen while compiling
the function. A stream is a variable or data structure that may be accessed repeatedly in a uniform
manner.
<!--l. 82--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">4.3.2   </span> <a 
href="#x11-330004.3.2" id="x11-330004.3.2">Variable-specific Performance Metrics</a></h4>
<!--l. 83--><p class="noindent" >For each variable that is encountered a significant number of times, MACPO shows the following performance
metrics:
     <dl class="description"><dt class="description">
<span 
class="cmbx-10">Estimated average cycles per access</span> </dt><dd 
class="description">                                                                          <br 
class="newline" />MACPO collects metrics that allow it to calculate the approximate reuse distance of variables. The
     reuse distance, in turn, helps to estimate the specific level of the cache that the request would have
     originated from. This makes it possible to estimate the number of cycles spent in each memory access.
     This cost in terms of memory access is grouped by the variable name and averaged to show in this
     metric.
     </dd><dt class="description">
<span 
class="cmbx-10">Dominant stride values and their percentages</span> </dt><dd 
class="description">                                                             <br 
class="newline" />A stride is the constant difference in bytes between the last memory access and the most recent memory
     access to a variable. MACPO computes the access strides in units of cache line size. This provides an
     indication of how well a code can be vectorized (stride of 0, <span 
class="cmti-10">i.e.</span>, sequential access, is best) and how
     one might optimize the code for better performance.
     </dd><dt class="description">
<span 
class="cmbx-10">Cache conflicts (thrashing) for L1 and L2 data caches</span> </dt><dd 
class="description">                                                   <br 
class="newline" />Cache conflicts arise when multiple processors, each with at least one private cache, repeatedly claim
     exclusive access to a portion of memory. This metric shows the percentage of requests to each level of
     the cache that conflicted with another access to the same variable.
     </dd><dt class="description">
<span 
class="cmbx-10">NUMA conflicts</span> </dt><dd 
class="description">                                                                                                    <br 
class="newline" />Most modern processors exhibit non-uniform memory access costs. The cost of memory access depends
     on whether the processor that hosts the memory controller managing the memory address is the same
     as the processor accessing the memory address. This metric displays the percentage of observed memory
     accesses that conflicted with another memory access to the same variable at the NUMA level.
     </dd><dt class="description">
<span 
class="cmbx-10">Reuse factors for L1, L2 and L3 data caches</span> </dt><dd 
class="description">                                                               <br 
class="newline" />From the observed reuse distance and a probabilistic model of set-associative caches, MACPO estimates
     whether a given memory access would be served out of L1 or would overflow the size of the cache,
     resulting in the memory access being served out of a higher (L2 or possibly L3) level of cache. This
                                                                                         
                                                                                         
     analysis permits MACPO to calculate the multicore reuse factor, which is a count of the number of
     times a given cache line is reused in a specific level of the cache.</dd></dl>
<!--l. 102--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">4.4   </span> <a 
href="#x11-340004.4" id="x11-340004.4">Improving Application Performance by Interpreting MACPO Metrics</a></h3>
<!--l. 104--><p class="noindent" >This section explains how to translate the MACPO metrics into source code changes to improve the performance of
your application.
     <dl class="description"><dt class="description">
<span 
class="cmbx-10">Estimated average cycles per access</span> </dt><dd 
class="description">                                                                          <br 
class="newline" />The cycles per access metric provides an overview of the performance of memory accesses to a specific
     variable.  It  makes  it  possible  to  identify  whether  a  particular  variable  is  suffering  from  memory
     performance bottleneck problems.
     </dd><dt class="description">
<span 
class="cmbx-10">Dominant stride values and their percentages</span> </dt><dd 
class="description">                                                             <br 
class="newline" />Programs that have unit strides or small regular stride values generally execute faster than programs
     that  have  long  or  irregular  access  strides.  There  are  several  factors  giving  better  memory  access
     performance. Since data is typically fetched from memory as cache lines, unit strides increase reuse.
     Hardware prefetchers can recognize small regular patterns in data accesses and bring data into caches
     before it is referenced, thus reducing data access penalty. Virtual address to physical address translation
     can also be serviced more efficiently (using TLBs) when the code exhibits unit strides.
     </dd><dt class="description">
<span 
class="cmbx-10">Cache conflicts (thrashing) for L1 and L2 data caches</span> </dt><dd 
class="description">                                                   <br 
class="newline" />Cache conflicts indicate thrashing between cache lines. By padding the data structures with additional
     (dummy) bytes, each thread can be made to access a different cache line, effectively removing cache
     conflicts.
     </dd><dt class="description">
<span 
class="cmbx-10">NUMA conflicts</span> </dt><dd 
class="description">                                                                                                    <br 
class="newline" />Most operating systems implement a first-touch policy by which the memory controller associated with
     the processor that first accesses the memory address &#8220;owns&#8221; the memory address. Memory accesses
     for the same address by a different processor result in NUMA conflicts. As a result, NUMA conflicts
     typically arise when one thread initializes a portion of memory that is then accessed by different
     threads. To avoid NUMA conflicts, have each processor initialize its own memory.
     </dd><dt class="description">
<span 
class="cmbx-10">Reuse factors for L1, L2 and L3 data caches</span> </dt><dd 
class="description">                                                               <br 
class="newline" />A low reuse factor indicates that a line is frequently evicted from the cache. The reuse factor can be
     improved by reducing the reuse distance of memory accesses.</dd></dl>
<!--l. 1--><div class="crosslinks"><p class="noindent">[<a 
href="user_manualch3.html" >prev</a>] [<a 
href="user_manualch3.html#tailuser_manualch3.html" >prev-tail</a>] [<a 
href="user_manualch4.html" >front</a>] [<a 
href="user_manual.html# " >up</a>] </p></div>
<!--l. 1--><p class="indent" >   <a 
 id="tailuser_manualch4.html"></a>   
</body></html> 
