\documentclass[titlepage]{report}

\usepackage{hyperref}
\usepackage{tikz}
\usepackage{fullpage}
\usetikzlibrary{shapes,shadows}
\tikzstyle{abstractbox}=[draw=black,fill=white,rectangle,inner sep=10pt,style=rounded corners,drop shadow={fill=black,opacity=1}]
\tikzstyle{abstracttitle}=[fill=white]
 
\newcommand{\nicebox}[3][fill=white]{
	\begin{center}
		\begin{tikzpicture}
			\node [abstractbox, #1] (box)
			{\begin{minipage}{0.95\linewidth}
				#3
			\end{minipage}};
			\node[abstracttitle, right=10pt] at (box.north west) {\textbf{#2}};
		\end{tikzpicture}
	\end{center}
}

\begin{document}

\title{{\Huge PerfExpert v4.0}\\ \ \\
	An Easy-to-Use Automatic Performance Diagnosis\\and Optimization Tool for HPC Applications\\ \ \\
    {\Huge User Manual}
}
\author{Leonardo Fialho\\
	\href{mailto:fialho@utexas.edu}{fialho@utexas.edu}\\ \ \\
	Ashay Rane\\
	\href{mailto:ashay.rane@tacc.utexas.edu}{ashay.rane@tacc.utexas.edu}\\ \ \\
	James Browne\\
	\href{mailto:browne@cs.utexas.edu}{browne@cs.utexas.edu}\\ \ \\
	\href{http://www.tacc.utexas.edu}{Texas Advanced Computing Center}\\
	\href{http://www.utexas.edu}{The University of Texas at Austin}}
\date{August 2013\\
	Revision 4}
\maketitle

\tableofcontents

\chapter{Introduction}

\section{Purpose}

HPC systems are notorious for operating at a small fraction of their peak performance. The ongoing migration to multi-core and multi-socket compute nodes further complicates performance optimization. The previously available performance optimization tools require considerable effort to learn and use. To enable wide access to performance optimization, TACC and its Technology Insertion partners have developed PerfExpert, a tool that combines a simple user interface with a sophisticated analysis engine to:

\begin{itemize}
  \item Detect and diagnosis the causes for any core-, socket-, and node-level performance bottlenecks in each procedure and loop of an application.
  \item Apply pattern-based software transformations on the application source code to enhance performance on identified bottlenecks.
  \item Provide performance analysis report and suggestions for bottleneck remediation for application's performance bottlenecks which we are unable to optimize automatically.
\end{itemize}

Applying PerfExpert requires only a single command line added to the application's usual job script. PerfExpert automates performance optimization at the core, socket and node levels as far as is possible. PerfExpert works with, and has been tested on, all Intel and AMD processors from Intel Nehalem and AMD 10h microarchitectures. PerfExpert is currently available only for the CPU portion of Stampede compute nodes but will be extended to Intel Many Integrated Cores (MICs) in the near future.

\section{People}

\textbf{James Browne}\\
Professor Emeritus of Computer Science, UT Austin\\
\href{mailto:browne@cs.utexas.edu}{browne@cs.utexas.edu}\\

\noindent\textbf{Leonardo Fialho}\\
Research Scientist, UT Austin\\
\href{mailto:fialho@utexas.edu}{fialho@utexas.edu}\\

\noindent\textbf{Ashay Rane}\\
PhD student, UT Austin\\
\href{mailto:ashay.rane@tacc.utexas.edu}{ashay.rane@tacc.utexas.edu}

\section{Publications}

\begin{itemize}
	\item Ashay Rane, James Browne, \textit{``Enhancing performance optimization of multicore chips and multichip nodes with data structure metrics''}, Parallel Architectures and Compilation Techniques (PACT) 2012.
	\item Ashay Rane, James Browne, Lars Koesterke: \textit{``A Systematic Process for Efficient Execution on Intel's Heterogeneous Computation Nodes''}, Extreme Science and Discovery Environment (XSEDE) 2012.
	\item Ashay Rane, James Browne, Lars Koesterke: \textit{``PerfExpert and MACPO: Which code segments should (not) be ported to MIC?''}, TACC-Intel Highly Parallel Computing Symposium, April 2012.
	\item Ashay Rane, James Browne: \textit{``Performance Optimization of Data Structures Using Memory Access Characterization''}. CLUSTER 2011: 570-574
	\item Ashay Rane, Saurabh Sardeshpande, James Browne: "Determining Code Segments that can Benefit from Execution on GPUs", poster presented at Supercomputing Conference (SC) 2011
	\item M. Burtscher, B.D. Kim, J. Diamond, J. McCalpin, L. Koesterke, and J. Browne. \textit{``PerfExpert: An Easy-to-Use Performance Diagnosis Tool for HPC Applications''}, SC 2010 International Conference for High-Performance Computing, Networking, Storage and Analysis. November 2010
	\item O. A. Sopeju, M. Burtscher, A. Rane, and J. Browne. \textit{``AutoSCOPE: Automatic Suggestions for Code Optimizations Using PerfExpert''}, 2011 International Conference on Parallel and Distributed Processing Techniques and Applications. July 2011
\end{itemize}

\section{Feedback}

If you have problems using PerfExpert on Stampede or Lonestar or suggestions for enhancing PerfExpert, contact us: \href{mailto:fialho@utexas.edu}{\texttt{fialho@utexas.edu}}. If you are reporting a problem, please try to include in your report a compressed file of the \texttt{.perfexpert-temp.XXXXXX} directory generated by the failed execution.

\section{Ways to Contribute}

Version 4 of PerfExpert has been designed to allow third-party contributions. There are several different ways to contribute with PerfExpert, such as:

\begin{itemize}
	\item Providing new bottleneck alleviation solutions.
	\item Creating new strategies to select bottleneck alleviation solutions based on performance metrics.
	\item Adding new performance metrics to PerfExpert.
	\item Writing modules to modify the source code in order to alleviate the identified bottlenecks.
\end{itemize}

Check section \ref{extending} to find some documentation on extending PerfExpert. If you would like to contribute to PerfExpert or need help to do research using PerfExpert, please contact us at \href{mailto:fialho@utexas.edu}{\texttt{fialho@utexas.edu}}. Complete directions on how to add to or modify each phase of PerfExpert can be found on the PerfExpert web site \href{https://bitbucket.org/leonardofialho/perfexpert/}{\texttt{https://bitbucket.org/leonardofialho/perfexpert/}}.

\section{Mailing List}

Out mailing list is hosted on Google Groups. To subscribe send a message to:\\
\href{subscribe-perfexpert@googlegroups.com}{\texttt{subscribe-perfexpert@googlegroups.com}} or access the group's webpage at:\\\href{https://groups.google.com/d/forum/perfexpert}{\texttt{https://groups.google.com/d/forum/perfexpert}}.

\section{Funding Sources}

The NSF Track 2 Ranger grant and the current NSF Stampede grant.

\chapter{Installation Instructions}

\section{Prerequisites}

PerfExpert is based on other tools so that installation of PerfExpert requires that they be installed. These tools are:

\begin{itemize}
	\item \textbf{PAPI} (\href{http://icl.cs.utk.edu/papi/software/}{\texttt{http://icl.cs.utk.edu/papi/software/}}): PAPI is required to measure hardware performance metrics like cache misses, branch instructions, etc. The PAPI installation is mostly straightforward: download, \texttt{./configure}, \texttt{make}, and \texttt{make install}. If your Linux kernel version is 2.6.32 or higher, then PAPI will mostly likely use \texttt{perf\_events}. Recent versions of PAPI (v3.7.2 and beyond) support using \texttt{perf\_events} in the Linux kernel. However, if your kernel version is lower than 2.6.32, then you would require patching the kernel with either \texttt{perfctr}\footnote{\href{http://user.it.uu.se/~mikpe/linux/perfctr/2.6/}{\texttt{http://user.it.uu.se/$\sim$mikpe/linux/perfctr/2.6/}}} or \texttt{perfmon}\footnote{\href{http://perfmon2.sourceforge.net/}{\texttt{http://perfmon2.sourceforge.net/}}}.
	\item \textbf{HPCToolkit} (\href{http://hpctoolkit.org/software.html}{\texttt{http://hpctoolkit.org/software.html}}): HPCToolkit is a tool that works on top of PAPI. HPCToolkit is used by PerfExpert to run the program multiple times with specific performance counters enabled. It is also useful for correlating addresses in the compiled binary back to the source code.
	\item \textbf{Java Virtual Machine} and the \textbf{Java Development Kit}\\(\href{http://www.oracle.com/technetwork/java/javase/downloads/}{\texttt{http://www.oracle.com/technetwork/java/javase/downloads/}}).
	\item \textbf{ROSE Compiler} (\href{http://rosecompiler.org/}{\texttt{http://rosecompiler.org/}}): ROSE is the framework PerfExpert uses to manipulate the application’s source code. It is required only if you wish to compile PerfExpert with performance optimization capability.
	\item \textbf{Apache Ant} (\href{http://ant.apache.org/bindownload.cgi}{\texttt{http://ant.apache.org/bindownload.cgi}}): it is required only to compile PerfExpert
	\item \textbf{SQLite} version 3 (\href{http://www.sqlite.org/}{\texttt{http://www.sqlite.org/}}): PerfExpert uses a SQLite database to store suggestions for bottleneck remediation and other information for automatic optimization.
	\item \textbf{GNU Multiple Precision Arithmetic Library} (\href{http://gmplib.org/}{\texttt{http://gmplib.org/}}): MACPO, one of the tools which compose PerfExpert requires this package.
	\item \textbf{Google SparseHash} (\href{https://code.google.com/p/sparsehash/}{\texttt{https://code.google.com/p/sparsehash/}}):\\MACPO, one of the tools which compose PerfExpert requires this package.
\end{itemize}

\subsection{Installing Prerequisites}

We provide a \texttt{INSTALL} script in the \texttt{perfexpert-externals-X.X.tar.gz} package. This script is an example of how to install some of PerfExpert prerequisites. To install PAPI, Java Virtual Machine, Java Development Kit, and SQLite follow the instructions of your Linux distribution.

\nicebox{CAUTION:}{The \texttt{INSTALL} script should be modified to fit for your environment. Do not run it out-of-the-box!}

\subsubsection{Apache Ant}

The PerfExpert externals package contains another package named \texttt{apache-ant-1.9.1-bin.tar.gz}. This is the binary version of Apache Ant. As PerfExpert only needs Apache Ant during compilation there is no need to install this package in your system. Thus, you should only decompress it. To do that, run the following commands:

\begin{verbatim}
$ tar -xzvf ./apache-ant-1.9.1-bin.tar.gz
$ export ANT_HOME=`pwd`/apache-ant-1.9.1
\end{verbatim}

\noindent these commands will decompress Apache Ant and set the \texttt{ANT\_HOME} environment variable to reflect the \texttt{PATH} where such package has been decompressed.

\subsubsection{HPCToolkit}

All HPCToolkit prerequisites are provided in the package \texttt{hpctoolkit-externals-5.3.2-r4197.tar.gz}. The PerfExpert externals package provides both HPCToolkit and HPToolkit prerequisites packages. To decompress and install the HPCToolkit prerequisites package run the following commands:

\begin{verbatim}
$ tar -xzvf ./hpctoolkit-externals-5.3.2-r4197.tar.gz
$ cd hpctoolkit-externals-5.3.2-r4197/
$ ./configure
$ make
\end{verbatim}

\nicebox{NOTICE:}{The HPCToolkit externals package does not has to be installed in your system, HPCToolkit will take care of this. However, it should be compiled and available during HPCToolkit compilation and installation process.}

After compiling the prerequisites for HPCToolkit, the HPCToolkit package can be installed. For that, run the following commands:

\begin{verbatim}
$ tar -xzvf ./hpctoolkit-5.3.2-r4197.tar.gz
$ cd hpctoolkit-5.3.2-r4197/
$ ./configure --prefix=WHERE_YOU_WANT_TO_INSTALL_IT \
    --with-externals=PATH_TO_HPCTOOLKIT_EXTERNALS_PACKAGE \
    --with-papi=PATH_TO_PAPI_INSTALLATION
$ make install
\end{verbatim}

\subsubsection{ROSE}

ROSE has several prerequisites. One of the most important one is the compiler. You should have \texttt{GCC} version 4.4 to compile ROSE. It also requires a specific version of the Boost library (1.47). We do provide the Boost library package, but to install \texttt{GCC} version 4.4 you should follow the instruction of your Linux distribution. To compile and install the Boost library version 1.47 run the following commands:

\nicebox{NOTICE:}{We had successfully compiled and installed ROSE using \texttt{GCC} 4.6, however according to the ROSE documentation this compiler is not supported. If you want to use this version of \texttt{GCC} do it carefully.}

\begin{verbatim}
$ tar -xzvf ./boost_1_47_0.tar.gz
$ cd boost_1_47_0/
$ ./bootstrap.sh
$ ./b2 install --prefix=${INSTALL_DIR}
\end{verbatim}

After installing successfully the Boost library run the following commands to compile and install ROSE:

\begin{verbatim}
$ tar -xzvf ./rose-0.9.5a-without-EDG-20584.tar.gz
$ cd rose-0.9.5a-20584/
$ mkdir _build
$ cd _build
$ ../configure --prefix=WHERE_YOU_WANT_TO_INSTALL_IT \
    --with-boost=WHERE_YOU_HAVE_INSTALLED_BOOST \
    --disable-tutorial-directory --disable-projects-directory \
    --disable-tests-directory --disable-opencl --disable-php \
    --disable-cuda --disable-binary-analysis --disable-java \
    --with-gomp_omp_runtime_library=WHERE_LIBGOMP_IS_INSTALLED \
    --libexecdir=/tmp --bindir=/tmp --sbindir=/tmp
$ make install
\end{verbatim}

\nicebox{NOTICE:}{The \texttt{configure} command we shown above avoids the compilation and installation of several features of ROSE. We do that to minimize the time required to compile ROSE. Moreover, some binaries that ROSE installs and we do not need them have been set to be installed into the \texttt{/tmp} directory. It is safe to clean the temporary directory after installing ROSE.}

\nicebox{ATTENTION:}{If you want to PerfExpert be able to optimize OpenMP applications you should set the \texttt{--with-gomp\_omp\_runtime\_library} argument to where \texttt{GCC} has installed \texttt{libgomp.so}.}

\subsubsection{GNU Multiple Precision Arithmetic Library}

Many Linux distributions already have the GNU Multiple Precision Arithmetic Library installed. To check if your system has it try to locate the \texttt{libgmp.so} file. If your system does not has the GNU Multiple Precision Arithmetic Library, run the following commands to install it:

\begin{verbatim}
$ tar -xzvf ./gmp-5.1.2.tar.gz
$ cd gmp-5.1.2/
$ ./configure --prefix=WHERE_YOU_WANT_TO_INSTALL_IT
$ make
$ make check
$ make install
\end{verbatim}

\nicebox{NOTICE:}{The GNU Multiple Precision Arithmetic Library is required to compile and execute MACPO, one of the tools which is part of PerfExpert. If you do not want to install MACPO you do not need to install the GNU Multiple Precision Arithmetic Library.}

\subsubsection{Google SparseHash}

To install Google SparseHash you should run the following commands:

\begin{verbatim}
$ tar -xzvf ./sparsehash-2.0.2.tar.gz
$ cd sparsehash-2.0.2/
$ ./configure --prefix=${INSTALL_DIR}
$ make install
\end{verbatim}

\nicebox{NOTICE:}{The Google SparseHash is required to compile and execute MACPO, one of the tools which is part of PerfExpert. If you do not want to install MACPO you do not need to install the Google SparseHash.}

\section{Downloading PerfExpert}

PerfExpert is an open-source project. Funding to keep researchers working on PerfExpert depends on the value of this tool to the scientific community. For that reason, it is really important to know where and who are using our tool. We would really appreciate it if you could send us a message (\href{mailto:fialho@utexas.edu}{\texttt{fialho@utexas.edu}}) telling us the institution (name and country) you are planning to install and test PerfExpert at.

The PerfExpert source code can be downloaded from the registration page:\\\href{http://www.tacc.utexas.edu/perfexpert/registration}{\texttt{http://www.tacc.utexas.edu/perfexpert/registration}}.

We encourage people to have a look on the wiki page, send patches, and raise issues on PerfExpert's page on BitBucket:\href{https://bitbucket.org/leonardofialho/perfexpert/}{\texttt{https://bitbucket.org/leonardofialho/perfexpert/}}.

\section{Setting up PerfExpert}

If you have downloaded PerfExpert from our version control system, you may have already noticed that there is no configure script available on the source code tree. To generate it run the following command:

\begin{verbatim}
$ ./autogen.sh
\end{verbatim}

\texttt{autogen.sh} requires the following packages available:

\begin{itemize}
	\item M4 version 1.4.13 or newer (\href{ftp://ftp.gnu.org/gnu/m4/}{\texttt{ftp://ftp.gnu.org/gnu/m4/}})
	\item Autoconf version 2.63 or newer (\href{ftp://ftp.gnu.org/gnu/autoconf/}{\texttt{ftp://ftp.gnu.org/gnu/autoconf/}})
	\item Automake version 1.11.1 or newer (\href{ftp://ftp.gnu.org/gnu/automake/}{\texttt{ftp://ftp.gnu.org/gnu/automake/}})
	\item Libtool version 2.2.6b or newer (\href{ftp://ftp.gnu.org/gnu/libtool/}{\texttt{ftp://ftp.gnu.org/gnu/libtool/}})
\end{itemize}

PerfExpert comes with a \texttt{Makefile}-base source code tree to automate the entire installation process. Thus the compilation and installation of PerfExpert is similar to any other GNU package:

\begin{verbatim}
$ ./configure
$ make
$ make install
\end{verbatim}

Optionally, you may want to run the set of test we have included into PerfExpert. To do so, just run ``\texttt{make check}'' after compiling your code.

If any of the prerequisites of PerfExpert are not on the \texttt{PATH} or \texttt{LD\_LIBRARY\_PATH}, you can specify the right locations of such files. For that, have a look on the configure script help using the following command:

\begin{verbatim}
$ ./configure --help
\end{verbatim}

A typical command line to run the \texttt{configure} may looks like this:

\begin{verbatim}
$ ./configure --prefix=WHERE_YOU_WANT_TO_INSTALL_IT \
    --with-rose=WHERE_ROSE_IS_INSTALLED \
    --with-jvm=WHERE_YOUR_JVM_IS_INSTALLED\
    --with-papi=WHERE_PAPI_IS_INSTALLED\
    --with-apache-ant=WHERE_YOU_HAVE_DECOMPRESSED_ANT
\end{verbatim}

Optionally, you may want to run the set of test we have included into PerfExpert. To do so, just run ``\texttt{make check}'' after compiling your code.

In case you have any problem installing PerfExpert, send us an email\\ (\href{fialho@utexas.edu}{\texttt{fialho@utexas.edu}}) or use our mailing list: \href{perfexpert@googlegroups.com}{\texttt{perfexpert@googlegroups.com}}.

\section{Characterizing your Machine}

During the installation process, PerfExpert will run a set of benchmark applications to characterize your machine. This characterization is used to analyze the performance of the applications you want to optimize. For that reason, you should be sure the PerfExpert installation is run on a machine of the same kind you are planning to run the production code on. If it is not possible, you should run the benchmark application and generate the characterization file manually and move it to the directory where PerfExpert has been installed. To do that you should execute the \texttt{hound} command (which is available inside the \texttt{bin} directory of PerfExpert installation) and save the output of this command to a file named \texttt{machine.properties} inside the \texttt{etc} directory where PerfExpert is installed.

\nicebox{ATTENTION:}{This is one of the most important and sensible steps of PerfExpert installation process. Be sure the content of this file reflects the characteristics of the machine where you want analyze the performance of applications. If the content of the \texttt{machine.properties} file is not accurate all the analysis, recommendations for optimization and also automatic optimization PerfExpert will do on your application could not improve it's performance.}

\section{Testing PerfExpert Installation}

We provide a set of tests you may want to run before using PerfExpert to optimize your applications. To run these tests you should run the following command inside the PerfExpert build tree:

\begin{verbatim}
$ make check
\end{verbatim}

It is normal that one of the tests (\texttt{mpi\_stampede}) fails since it has been designed to be executed only on Stampede.

\chapter{Using PerfExpert}

The objective of this chapter is to explain how to run programs using PerfExpert and how to interpret its output using a simple matrix multiplication program. In this chapter, we will use the OpenMP simple matrix multiplication program\footnote{\href{https://computing.llnl.gov/tutorials/openMP/samples/C/omp\_mm.c}{\texttt{https://computing.llnl.gov/tutorials/openMP/samples/C/omp\_mm.c}}}. This program multiplies two matrices and prints one value from the resulting matrix.

\nicebox{CAUTION:}{PerfExpert may, if you choose to use the full capabilities for automated optimization, change your source code during the process of optimization. PerfExpert  always saves the original file with a different name (\textit{e.g.}, \texttt{omp\_mm.c.old\_27301}) as well as adding annotations to your source code for each optimization it makes. We cannot, however, fully guarantee that code modifications for optimizations will not break your code. We recommend having a full backup of your original source code before using PerfExpert.}

\section{Environment Configuration}

If you are using any of the TACC\footnote{\href{https://www.tacc.utexas.edu/}{\texttt{https://www.tacc.utexas.edu/}}} machines, load the appropriate modules:

\begin{verbatim}
$ module load papi hpctoolkit perfexpert
\end{verbatim}

The runs with PerfExpert should be made using a data set size for each compute node which is equivalent to full production runs but for which execution time is not more than about ten or fifteen minutes since PerfExpert will run your application multiple times (actually, three times on Stampede) with different performance counters enabled. For that reason, before you run PerfExpert you should either request iterative access to computational resources (compute node), or modify the job script that you use to run your application and specify a running time that is about 3 (for Stampede) or 6 (for Lonestar) times the normal running time of the program.

To request iterative access to a compute node on Stampede, please, have a look on the User Guide\footnote{\href{https://portal.tacc.utexas.edu/group/tup/user-guides/stampede\#running}{\texttt{https://portal.tacc.utexas.edu/group/tup/user-guides/stampede\#running}}}.

Below is an example of a job script file modified to use PerfExpert which runs PerfExpert on the application named my\_program and generate the performance analysis report. Adding command line options will cause suggestions for bottleneck remediation to be generated and output and/or automatic performance optimization to be attempted. 

\pagebreak
\noindent\hrulefill
\begin{verbatim}
#!/bin/bash

# job name
#SBATCH -J myMPI

# output and error filename (%j stands to jobID)
#SBATCH -o myMPI.o%j

# total number of mpi tasks requested
#SBATCH -n 16

# queue (partition) -- normal, development, etc.
#SBATCH -p development

# run time (hh:mm:ss) - 1.5 hours
#SBATCH -t 01:30:00

# run the executable named my_program
perfexpert 0.1 ./my_program
\end{verbatim}\hrulefill
	
\section{PerfExpert Options}

There are several different options for applying PerfExpert. The following summary shows you how to choose the options to run PerfExpert to match your needs.

\begin{verbatim}
$ perfexpert -h
Usage: perfexpert <threshold> [-gvch] [-l level] [-d database] [-r count] [-p prefix]
                   [-m target|-s sourcefile] [-a FILE] [-b FILE] <program_executable>
                   [program_arguments]

 <threshold>        Define the relevance (in % of runtime) of code fragments PerfExpert 
                    should take into consideration (> 0 and <= 1)
 -d --database      Select the recommendation database file
 -r --recommend     Number of recommendation to show
 -m --makefile      Use GNU standard 'make' command to compile
                    the code (it requires the source code
                    available in current directory)
 -s --source        Specify the source code file (if your source code has more than one 
                    file please use a Makefile and choose -m option it also enables
                    automatic optimization (-a)
 -p --prefix        Add a prefix to the command line (e.g. mpirun) use double quotes to 
                    specify multiple arguments (e.g. -p "mpirun -n 2"
 -b --before        Execute FILE before each run of the
                    application
 -a --after         Execute FILE after each run of the application
 -v --verbose       Enable verbose mode using default verbose level (1)
 -l --verbose_level Enable verbose mode using specific verbose level (1-10)
 -c --colorful      Enable colors on verbose mode, no weird characters will appear on
                    output files
 -h --help          Show this message

Use CC, CFLAGS and LDFLAGS to select compiler and compilation/linkage flags
\end{verbatim}

If you select the \texttt{-m} or \texttt{-s} options, PerfExpert will try to automatically optimize your code and show you the performance analysis report \& the list of suggestion for bottleneck remediation when no automatic optimization is possible.

For the \texttt{-m} or \texttt{-s} options, PerfExpert requires access to the application source code. If you select the \texttt{-m} option and the application is composed of multiple files, your source code tree should have a \texttt{Makefile} file to enable PerfExpert compile your code. If your application is composed of a single source code file, the option \texttt{-s} is sufficient for you. If you do not select \texttt{-m} or \texttt{-s} options, PerfExpert requires only the binary code and will show you only the performance analysis report and the list of suggestion for bottleneck remediation.

PerfExpert will run your application multiple times to collect different performance metrics. You may use the \texttt{-b} (or \texttt{-a}) options if you want to execute a program or script before (or after) each run. The argument \texttt{program\_executable} should be the filename of the application you want to analyze, not a shell script, otherwise, PerfExpert will analyze the performance of the shell script instead of the performance of you application.

Use the \texttt{-r} option to select the number of recommendations for optimization you want for each code section which is a performance bottleneck.

\nicebox{CAUTION:}{If your program takes any argument that starts with a ``\texttt{-}'' signal PerfExpert will interpret this as a command line option. To help PerfExpert handle \texttt{program\_arguments} correctly, use quotes and add a space before the program's arguments (e.g., ``\texttt{ -s 50}'').}

\nicebox{CAUTION:}{In case you are trying to optimize a MPI application, you should use the \texttt{-p} option to specify the MPI launcher and also it's arguments.}

For this guide, using the OpenMP simple matrix multiply code, we will use the following command line options:

\begin{verbatim}
$ OMP_NUM_THREADS=16 CFLAGS="-fopenmp" perfexpert -s mm_omp.c 0.05 mm_omp
\end{verbatim}

which executes PerfExpert's automatic optimizations and will also generate an OpenMP-enabled binary which will run with 16 threads. In this case, PerfExpert will compile the \texttt{mm\_omp.c} code using the system's default compiler, which is GCC in the case of Stampede. PerfExpert will take into consideration only code fragments (loops and functions) that take more 5\% of the runtime.

To select a different compiler, you should specify the \texttt{CC} environment variable as below:

\begin{verbatim}
$ CC="icc" OMP_NUM_THREADS=16 CFLAGS="-fopenmp" perfexpert -s mm_omp.c 0.05 mm_omp
\end{verbatim}

\nicebox{WARNING:}{If the command line you use to run PerfExpert includes the MPI launcher (\textit{i.e.}, \texttt{mpirun -n 2 my\_mpi\_app my\_mpi\_app\_arguments ...}), PerfExpert will analyze the performance of the MPI launcher instead of the performance of your application. Use the \texttt{-p} command line argument of PerfExpert to set the MPI launcher and all its arguments (\textit{e.g.}, \texttt{-p "mpirun -n 16"}).}

\section{The Performance Analysis Report}

This section explains the performance analysis report and the metrics shown by PerfExpert. We discuss the following sample output:

\begin{verbatim}
Loop in function compute() (99.9% of the total runtime)
=========================================================================
ratio to total instrns       %  0.......25.........50.......75......100
   - floating point      :    6 ***
   - data accesses       :   33 ****************

* GFLOPS (% max)         :    7 ***
   - packed              :    0 *
   - scalar              :    7 ***
-----------------------------------------------------------------------
performance assessment     LCPI good....okay....fair....poor....bad...
* overall                :  0.8 >>>>>>>>>>>>>>>>
upper bound estimates
* data accesses          :  2.4 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>+
   - L1d hits            :  1.3 >>>>>>>>>>>>>>>>>>>>>>>>>
   - L2d hits            :  0.3 >>>>>
   - L2d misses          :  0.8 >>>>>>>>>>>>>>>>
* instruction accesses   :  0.3 >>>>>>
   - L1i hits            :  0.3 >>>>>>
   - L2i hits            :  0.0 >
   - L2i misses          :  0.0 >
* data TLB               :  1.5 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
* instruction TLB        :  0.0 >
* branch instructions    :  0.0 >
   - correctly predicted :  0.0 >
   - mispredicted        :  0.0 >
* floating-point instr   :  0.2 >>>>
   - fast FP instr       :  0.2 >>>>
   - slow FP instr       :  0.0 >
\end{verbatim}

Apart from the total running time, PerfExpert performance analysis report includes, for each code segment:

\begin{itemize}
	\item Instruction execution ratios (with respect to total instructions);
	\item Approximate information about the computational efficiency (GFLOPs measurements);
	\item Overall performance;
	\item Local Cycles Per Instruction (LCPI) values for the cost of memory accesses.
\end{itemize}

The program composition part shows what percentage of the total instructions were computational (floating-point instructions) and what percentage were instructions that accessed data. This gives a rough estimate in trying to understand whether optimizing the program for either data accesses or floating-point instructions would have a significant impact on the total running time of the program.

The PerfExpert performance analysis report also shows the GFLOPs rating, which is the number of floating-point operations executed per second in multiples of 109. The value for this metric is displayed as a percentage of the maximum possible GFLOP value for that particular machine. Although it is rare for real-world programs to match even 50\% of the maximum value, this metric can serve as an estimate of how efficiently the code performs computations.

The next, and major, section of the PerfExpert performance analysis report shows the LCPI values, which is the ratio of cycles spent in the code segment for a specific category, divided by the total number of instructions in the code segment. The overall value is the ratio of the total cycles taken by the code segment to the total instructions executed in the code segment. 

Generally, a value of 0.5 or lower for an LCPI is considered to be good. However, it is only necessary to look at the ratings (\texttt{good}, \texttt{okay}, \ldots, \texttt{bad}) The rest of the report maps this overall LCPI, into the six constituent categories: data accesses, instruction accesses, data TLB accesses, instruction TLB accesses, branches and floating point computations. Without getting into the details of instruction operation on Intel and AMD chips, one can say that these six categories record performance in non-overlapping ways. That is, they roughly represent six separate categories of performance for any application.

The LCPI value is a good indicator of the cost arising from instructions of the specific category. Hence, the higher the LCPI, the slower the program. The following is a brief description of each of these categories:

\begin{description}
	\item[Data accesses:]\hfill \\
	counts the LCPI arising from accesses to memory for program variables.
	\item[Instruction accesses:]\hfill \\
	counts the LCPI arising from memory accesses for code (functions and loops).
	\item[Data TLB:]\hfill \\
	provides an approximate measure of penalty arising from strides in accesses or regularity of accesses.
	\item[Instruction TLB:]\hfill \\
	reflects cost of fetching instructions due to irregular accesses.
	\item[Branch instructions:]\hfill \\
	counts cost of jumps (i.e. if statements, loop conditions, etc.).
	\item[Floating-point instructions:]\hfill \\
	counts LCPI from executing computational (floating-point) instructions.
\end{description}

Some of these LCPI categories have subcategories. For instance, the LCPI from data and instruction accesses can be divided into LCPI arising from the individual levels of the data and instruction caches and branch LCPIs can be divided into LCPIs from correctly predicted and from mispredicted branch instructions. For floating-point instructions, the division is based on floating-point instructions that take few cycles to execute (\textit{e.g.}, add, subtract and multiply instructions) and on floating-point instructions that take longer to execute (\textit{e.g.}, divide and square-root instructions).

In each case, the classification (data access, instruction access, data TLB, etc.) is shown so that it is easy to understand which category is responsible for the performance slowdown. For instance if the overall CPI is ``\texttt{poor}'' and the data access LCPI is high, then you should concentrate on access to program variables and memory. Additional LCPI details help in relating performance numbers to the process architecture.

\nicebox{IMPORTANT:}{When PerfExpert runs with automatic performance optimization enabled the performance analysis report shown reflects the performance of the code after all possible automatic optimizations have been applied.}

\nicebox{NOTICE:}{PerfExpert creates a \texttt{.perfexpert-temp.XXXXXX} directory for each time it is executed. This directory has one subdirectory for each optimization cycle PerfExpert completed or attempted. Each subdirectory includes the intermediate files PerfExpert generated during each cycle, including the performance analysis reports.}

\section{List of Recommendations for Optimization}

If PerfExpert runs with \texttt{-–r} option enabled, it will also generate a list of suggestions for performance improvement for each bottleneck. This option is always available, it does not depend on which of the other command line option are. A list of suggestions for this example is shown below:

\begin{verbatim}
#--------------------------------------------------
# Recommendations for /work/02204/fialho/tutorial/3/mm_omp.c:14
#--------------------------------------------------
#
# Here is a possible recommendation for this code segment
#
Description: move loop invariant computations out of loop
Reason: this optimization reduces the number of executed floating-point operations
Code example:
loop i
  x = x + a * b * c[i];
 =====>
temp = a * b;
loop i
  x = x + temp * c[i];

#
# Here is a possible recommendation for this code segment
#
Description: change the order of loops
Reason: this optimization may improve the memory access pattern and make it more cache 
and TLB friendly
Code example:
loop i
  loop j {...}
 =====>
loop j
  loop i {...}

#
# Here is a possible recommendation for this code segment
#
Description: componentize important loops by factoring them into their own subroutines
Reason: this optimization may allow the compiler to optimize the loop independently and
thus tune it better
Code example:
loop i {...}
...
loop j {...}
 =====>
void li() { loop i {...} }
void lj() { loop j {...} }
...
li();
...
lj();
\end{verbatim}

\chapter{Using MACPO}
MACPO is an acronym for Memory Access Characterization for Performance Optimization. It is a tool that has been built to assist performance tuning of single- and multi-threaded C, C++ or Fortran applications. More specifically, MACPO is designed to provide insight into an application's memory usage patterns.

\section{A quick demonstration}
To demonstrate the functioning of MACPO, let's consider an example program. This program uses Pthreads to calculate the value of Pi using the Monte-Carlo method.

The following code shows the function that is executed by each thread:
\begin{verbatim}
void* thread_func (void* arg)
{
  int idx;
  float x, y, z;
  thread_info_t* thread_info = (thread_info_t*) arg;
  for (int repeat=0; repeat<REPEAT_COUNT; repeat++)
  {
    for (int i=0; i<ITERATIONS; i++)
    {
      idx = i+thread_info->tid;
      x = random_numbers[idx%RANDOM_BUFFER_SIZE];
      y = random_numbers[(1+idx)%RANDOM_BUFFER_SIZE];

      z = x*x + y*y;
      if (z <= 1) counts[thread_info->tid]++;
    }
  }

  pthread_exit(0);
}
\end{verbatim}

To compile the application using MACPO, indicating that we are interested in understanding the performance metrics associated with the \texttt{thread\_func} function, run the following commands:
\begin{verbatim}
$ macpo.sh --macpo:function=thread_func -c monte-carlo.cc
$ macpo.sh --macpo:function=thread_func monte-carlo.o -o monte-carlo -lpthread -lrt
\end{verbatim}

Runtime logs (macpo.out) are produced when the application is run:
\begin{verbatim}
$ ./monte-carlo
\end{verbatim}

To print performance metrics, use the \texttt{macpo-analyze} program.
\begin{verbatim}
$ macpo-analyze macpo.out
\end{verbatim}

This will produce an output that is similar to the one shown below:
\begin{verbatim}
Var "counts", seen 1668 times, estimated to cost 147.12 cycles on every access.
Stride of 0 cache lines was observed 1585 times (100.00%).

Level 1 data cache conflicts = 78.22% [################################        ]
Level 2 data cache conflicts = 63.37% [##########################              ]
NUMA data conflicts = 43.56%          [##################                      ]

Level 1 data cache reuse factor = 97.0% [####################################### ]
Level 2 data cache reuse factor = 3.0% [##                                      ]
Level 3 data cache reuse factor = 0.0% [                                        ]
\end{verbatim}

The output shows the estimated cost of memory accesses (147.12 cycles) to the variable \texttt{counts} in terms of cycles per access\footnote{A large number of cycles indicates poor memory performance. Causes of large values may be explained by the following metrics.}. The output also shows stride values (0 cache lines) observed in the accesses to the variable\footnote{A stride of 0 cache lines indicates that subsequent references are in the same cache line; this indicates good memory performance and is good for vectorization. A stride of $n$ indicates that subsequent references are $n$ cache lines apart; the larger $n$, the worse is the memory performance.}. As per the cache conflicts shown in the output, accesses to the variable \texttt{counts} suffer from both L1 and L2 cache conflicts (also known as cache thrashing). Using this knowledge, we can pad the \texttt{counts} array (i.e., add dummy bytes to the array) so that each thread running on a core and, thus, sharing an L1 cache as well as the shared L2 cache, which may be shared by other cores, accesses a different cache line. This optimization reduces the running time of the \texttt{thread\_func} routine from 9.14s to 3.17s.

The other information provided by MACPO is discussed below in Section \ref{sec:macpo-metrics}.

\section{When to use MACPO}
MACPO may be useful to you in any of the following situations:

\begin{itemize}
\item Perfexpert reports that L2 or L3 data access LCPI is high.
\item Your program uses a lot of memory or it is memory-bound.
\item CPU profiling does not show any interesting results.
\end{itemize}

If all (or most) of your application's memory accesses are irregular, you may be able to infer the optimizations applicable to your program. However, for such programs, MACPO metrics may not be able to assist you directly.

\section{MACPO metrics}
\label{sec:macpo-metrics}
Performance information shown by MACPO can be grouped into two parts. The first part shows information that is applicable to the entire function being profiled. The second part shows information that is specific to the important variables in the function.

\subsection{Function-wide performance metrics}
Currently, function-wide information only shows the number of streams that were seen while compiling the function. A stream is a variable or data structure that may be accessed repeatedly in a uniform manner.

\subsection{Variable-specific performance metrics}
For each variable that is encountered a significant number of times, MACPO shows the following performance metrics:

\begin{enumerate}
\item Estimated average cycles per access
\item Dominant stride values and their percentages
\item Cache conflicts (thrashing) for level 1 and level 2 data caches
\item NUMA conflicts
\item Reuse factors for level 1, 2 and 3 data caches
\end{enumerate}

The following sections explain each of the above metrics.

\subsubsection{Estimated average cycles per accesses}
MACPO collects metrics that allow it to calculate the approximate reuse distance of variables. The reuse distance, in turn, helps to estimate the specific level of the cache that the request would have originated from. This makes it possible to estimate the number of cycles spent in each memory access. This cost in terms of memory access is grouped by the variable name and averaged to show in this metric.

\subsubsection{Dominant stride values and percentages}
A stride is the constant difference in bytes between the last memory access and the most recent memory access to a variable. MACPO computes the access strides in units of cache line size. This provides an indication of how well a code can be vectorized (stride of 0, i.e., sequential access, is best) and how one might optimize the code for better performance.

\subsubsection{Cache conflicts for level 1 and level 2 data caches}
Cache conflicts arise when multiple processors, each with at least one private cache, repeatedly claim exclusive access to a portion of memory. This metric shows the percentage of requests to each level of the cache that conflicted with another access to the same variable.

\subsubsection{NUMA conflicts}
Most modern processors exhibit non-uniform memory access costs. The cost of memory access depends on whether the processor that hosts the memory controller managing the memory address is the same as the processor accessing the memory address. This metric displays the percentage of observed memory accesses that conflicted with another memory access to the same variable at the NUMA level.

\subsubsection{Reuse factors for level 1, 2 and 3 data caches}
From the observed reuse distance and a probabilistic model of set-associative caches, MACPO estimates whether a given memory access would be served out of L1 or would overflow the size of the cache, resulting in the memory access being served out of a higher (L2 or possibly L3) level of cache. This analysis permits MACPO to calculate the multicore reuse factor, which is a count of the number of times a given cache line is reused in a specific level of the cache.

\section{Interpreting MACPO metrics}
This section explains how to translate the MACPO metrics into source code changes to improve the performance of your application.

\subsection{Cycles per access}
The cycles per access metric provides an overview of the performance of memory accesses to a specific variable. It makes it possible to identify whether a particular variable is suffering from memory performance bottleneck problems.

\subsection{Dominant stride values and percentages}
Programs that have unit strides or small regular stride values generally execute faster than programs that have long or irregular access strides. There are several factors giving better memory access performance. Since data is typically fetched from memory as cache lines, unit strides increase reuse. Hardware prefetchers can recognize small regular patterns in data accesses and bring data into caches before it is referenced, thus reducing data access penalty. Virtual address to physical address translation can also be serviced more efficiently (using TLBs) when the code exhibits unit strides.

\subsection{Cache conflicts}
Cache conflicts indicate thrashing between cache lines. By padding the data structures with additional (dummy) bytes, each thread can be made to access a different cache line, effectively removing cache conflicts.

\subsection{NUMA conflicts}
Most operating systems implement a first-touch policy by which the memory controller associated with the processor that first accesses the memory address ``owns'' the memory address. Memory accesses for the same address by a different processor result in NUMA conflicts.  As a result, NUMA conflicts typically arise when one thread initializes a portion of memory that is then accessed by different threads. To avoid NUMA conflicts, have each processor initialize its own memory.

\subsection{Reuse factors for level 1, 2 and 3 data caches}
A low reuse factor indicates that a line is frequently evicted from the cache. The reuse factor can be improved by reducing the reuse distance of memory accesses.

\chapter{List of Automatic Optimizations PerfExpert Supports}

\chapter{PerfExpert for Advanced Users}

\section{Tools Which Are Part of PerfExpert}

\subsection{\texttt{macpo}}
\subsection{\texttt{recommender}}
\subsection{\texttt{perfexpert\_ct}}

\section{PerfExpert Temporary Directory}

\section{Command Line Arguments Unveiled}

\section{Re-Analyzing the Results from a Previous PerfExpert Run}

\section{Using Environment Variables}

Here is the list of all the environment variables PerfExpert uses. The command line arguments overwrite the value set by any of the environment variables. PerfExpert automatically sets the \texttt{PERFEXPERT\_RECOMMENDER\_*} and \texttt{PERFEXPERT\_CT\_*} variables, but it will not overwrite the value of them if they are already set. Thus, it is possible to use these environment variables to pass options to \texttt{recommender} and \texttt{perfexpert\_ct}.

\begin{description}
	\item[\texttt{PERFEXPERT\_MAKE\_TARGET}]\hfill \\
	This variable has the same functionality than the \texttt{-m} command line option. It's value is passed to \texttt{make} to compile the source code while using a \texttt{Makefile} (\textit{e.g.}, \texttt{make all}). If this variable is set while the user selects the \texttt{-s} command line option an error will be generated.

	\item[\texttt{PERFEXPERT\_SOURCE\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-s} command line option. It's value should be a valid source code file which will be compiled to obtain the binary executable. If this variable is set while the user selects the \texttt{-m} command line option an error will be generated.

	\item[\texttt{PERFEXPERT\_DATABASE\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-d} command line option. It's value should be a valid PerfExpert database file. By default, PerfExpert uses the \texttt{.perfexpert.db} database file located in the user \texttt{\$HOME} directory. If this file does not exist, PerfExpert will copy it from the installation directory.

	\item[\texttt{PERFEXPERT\_REC\_COUNT}]\hfill \\
	This variable has the same functionality than the \texttt{-r} command line option. It's value should be a valid integer number higher than \texttt{0}.

	\item[\texttt{PERFEXPERT\_VERBOSE\_LEVEL}]\hfill \\
	This variable has the same functionality than the \texttt{-l} command line option. It's value should be a valid integer number within \texttt{1} and \texttt{10}.

	\item[\texttt{PERFEXPERT\_COLORFUL}]\hfill \\
	This variable has the same functionality than the \texttt{-c} command line option. It's value should be \texttt{0} or \texttt{1}.
	
	\item[\texttt{CC}]\hfill \\
	This variable sets the compiler PerfExpert should use to obtain the binary executable. It should be a valid executable file. It is possible to set it's value to include the compiler's full path. The value of this variable has no effect when PerfExpert runs without the \texttt{-s} command line option and the \texttt{PERFEXPERT\_SOURCE\_FILE} environment variable is not set. Also, note that the value of this variable has no effect when PerfExpert uses \texttt{Makefile} to obtain the binary executable.

	\item[\texttt{CFLAGS}]\hfill \\
	This variable sets the compiler flags PerfExpert should use while compiling the source code. The value of this variable has no effect when PerfExpert runs without the \texttt{-s} command line option and the \texttt{PERFEXPERT\_SOURCE\_FILE} environment variable is not set. Also, note that the value of this variable has no effect when PerfExpert uses \texttt{Makefile} to obtain the binary executable.

	\item[\texttt{PERFEXPERT\_CFLAGS}]\hfill \\
	This variable is used by PerfExpert to implement optimization which depends upon compiler flags. This variable should not be used to pass any user defined compiler flags because it's content will be freely modified by PerfExpert.

	\item[\texttt{PERFEXPERT\_RECOMMENDER\_INPUT\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-f} command line option. It should be a valid readable file. It is possible to set it's value to include a full path. PerfExpert automatically sets the value of this variable.
	
	\item[\texttt{PERFEXPERT\_RECOMMENDER\_OUTPUT\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-o} command line option.  It is possible to set it's value to include a full path. PerfExpert automatically sets the value of this variable.

	\item[\texttt{PERFEXPERT\_RECOMMENDER\_DATABASE\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-d} command line option. It's value should be a valid PerfExpert database file. By default, PerfExpert sets the value of this variable to the database it is using.

	\item[\texttt{PERFEXPERT\_RECOMMENDER\_METRICS\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-m} command line option. It should be a valid readable file. It is possible to set it's value to include a full path.
	
	\item[\texttt{PERFEXPERT\_RECOMMENDER\_REC\_COUNT}]\hfill \\
	This variable has the same functionality than the \texttt{-r} command line option. It's value should be a valid integer number higher than \texttt{0}. By default, PerfExpert sets the value of this variable to value it is set to run with.

	\item[\texttt{PERFEXPERT\_RECOMMENDER\_WORKDIR}]\hfill \\
	The variable controls where \texttt{recommender} will generate intermediary files used for automatic optimization. The value of this variable is automatically set by PerfExpert and it the same working directory the \texttt{perfexpert} itself uses. Usually, it's value is like \texttt{.perfexpert-temp.XXXXXX}.

	\item[\texttt{PERFEXPERT\_RECOMMENDER\_PID}]\hfill \\
	This variable is used by PerfExpert to identify calls to \texttt{recommender} during the same execution but in a different optimization cycle. It is automatically set by PerfExpert and it's value is the PID of the \texttt{perfexpert} process.

	\item[\texttt{PERFEXPERT\_RECOMMENDER\_VERBOSE\_LEVEL}]\hfill \\
	This variable has the same functionality than the \texttt{-l} command line option. It's value should be a valid integer number within \texttt{1} and \texttt{10}. By default, PerfExpert sets the value of this variable to value it is set to run with.

	\item[\texttt{PERFEXPERT\_RECOMMENDER\_COLORFUL}]\hfill \\
	This variable has the same functionality than the \texttt{-c} command line option. It's value should be \texttt{0} or \texttt{1}. By default, PerfExpert sets the value of this variable to value it is set to run with.

	\item[\texttt{PERFEXPERT\_CT\_INPUT\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-f} command line option. It should be a valid readable file. It is possible to set it's value to include a full path. PerfExpert automatically sets the value of this variable.

	\item[\texttt{PERFEXPERT\_CT\_OUTPUT\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-o} command line option.  It is possible to set it's value to include a full path. PerfExpert automatically sets the value of this variable.

	\item[\texttt{PERFEXPERT\_CT\_DATABASE\_FILE}]\hfill \\
	This variable has the same functionality than the \texttt{-d} command line option. It's value should be a valid PerfExpert database file. By default, PerfExpert sets the value of this variable to the database it is using.

	\item[\texttt{PERFEXPERT\_CT\_WORKDIR}]\hfill \\
	The variable controls where \texttt{recommender} will generate intermediary files used for automatic optimization. The value of this variable is automatically set by PerfExpert and it the same working directory the \texttt{perfexpert} itself uses. Usually, it's value is like \texttt{.perfexpert-temp.XXXXXX}.

	\item[\texttt{PERFEXPERT\_CT\_PID}]\hfill \\
	This variable is used by PerfExpert to identify calls to \texttt{perfexpert\_ct} during the same execution but in a different optimization cycle. It is automatically set by PerfExpert and it's value is the PID of the \texttt{perfexpert} process.

	\item[\texttt{PERFEXPERT\_CT\_VERBOSE\_LEVEL}]\hfill \\
	This variable has the same functionality than the \texttt{-l} command line option. It's value should be a valid integer number within \texttt{1} and \texttt{10}. By default, PerfExpert sets the value of this variable to value it is set to run with.

	\item[\texttt{PERFEXPERT\_CT\_COLORFUL}]\hfill \\
	This variable has the same functionality than the \texttt{-c} command line option. It's value should be \texttt{0} or \texttt{1}. By default, PerfExpert sets the value of this variable to value it is set to run with.
\end{description}

\chapter{Extending PerfExpert}
\label{extending}

\section{Database Layout}

\section{Adding Metrics to PerfExpert}

\section{New Recommendations for Optimization}

\section{Enabling New Automatic Optimizations}

\end{document}
